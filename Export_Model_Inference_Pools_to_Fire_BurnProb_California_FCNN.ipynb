{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Export Model Inference - Pools to Fire BurnProb California FCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyle-woodward/EEpythonNotebooks/blob/main/Export_Model_Inference_Pools_to_Fire_BurnProb_California_FCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTn7SAZ3l9FI"
      },
      "source": [
        "# Pools to Fire BurnProb California FCNN\n",
        "## Use a deployed AI platform EEified model to create and export inference images\n",
        "## downloads and reads in the sample_.json and modelname.json dictionaries to automatically setup feature stack and AI model for inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrPDt_XAmFsD"
      },
      "source": [
        "## Setting up the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOKSNcUxm9lz"
      },
      "source": [
        "### Importing packages and checking versions\n",
        "\n",
        "codecarbon only works after installing and then reseting the notebook. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install codecarbon"
      ],
      "metadata": {
        "id": "NQ0zmXgoOerb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure out which region you are in with the command below. Training requires many reads from GCP. If your bucket is located halfway across the world from your instance do a Factory Resart and check again. "
      ],
      "metadata": {
        "id": "Sbrjf3H5NtKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipinfo.io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u42Mdbxu1nzF",
        "outputId": "3f041c5f-8a18-4af7-e102-39da8260dfb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"ip\": \"34.148.229.157\",\n",
            "  \"hostname\": \"157.229.148.34.bc.googleusercontent.com\",\n",
            "  \"city\": \"North Charleston\",\n",
            "  \"region\": \"South Carolina\",\n",
            "  \"country\": \"US\",\n",
            "  \"loc\": \"32.8546,-79.9748\",\n",
            "  \"org\": \"AS15169 Google LLC\",\n",
            "  \"postal\": \"29415\",\n",
            "  \"timezone\": \"America/New_York\",\n",
            "  \"readme\": \"https://ipinfo.io/missingauth\"\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F4TL_6zPHzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d858235a-0b27-40f4-bb2e-b03f9b809816"
      },
      "source": [
        "import os\n",
        "# Cloud authentication.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "# from codecarbon import EmissionsTracker\n",
        "\n",
        "# tracker = EmissionsTracker()\n",
        "# tracker.start()\n",
        "# get numpy and matplotlib.pyplot\n",
        "%pylab inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgcgnC_Lg8CB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2e8dd1-fd64-4f0a-d285-779ab4779922"
      },
      "source": [
        "# Import, authenticate and initialize the Earth Engine library.\n",
        "import ee\n",
        "try:\n",
        "    ee.Initialize()\n",
        "except Exception as e:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=zxO7ks-UDdjE8714dLwv4He6YgO3mCLmFPGl01zl88c&tc=T_mWuvFSIN6HH-MlMVxvvcNW4srqI8bWTlJS4eQuk5s&cc=pzvSN7SODHDNEy0tIHQ9lDnJDUGiynXJrsdCxcDOrTU\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/1AX4XfWh83UhHiXF82z6uuo4lN0cKDQDkshXmoX9II2XvZKnakm7L4Yq7znE\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "vP3how4c_ZIg",
        "outputId": "061e7885-3cf2-4c37-d9ed-e2f3a6e03b43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_ixFWWln9RN"
      },
      "source": [
        "# Folium setup.\n",
        "# import folium\n",
        "# print(folium.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load sample and model .json files"
      ],
      "metadata": {
        "id": "X-8VM1RSh2yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "model_name = 'vgg16unet_model_kdw_sigmoid_mae_v18_rev2' # without a file extension\n",
        "vers = 'v18_rev2'\n",
        "\n",
        "# load sample .json made from SampleGeneration/ModelTraining workflow\n",
        "sample_json= os.popen(f'gsutil ls gs://landfire/lucas/pools2fire_tf/sample_{vers}*.json').read().split('\\n')[:-1][-1] # download latest sample version .json if there's more than one of same version\n",
        "#print(sample_json)\n",
        "local = sample_json.split('/')[-1]\n",
        "!gsutil cp $sample_json $local\n",
        "with open(local) as f:\n",
        "  model_dict = json.load(f)\n",
        "print('tf model info',model_dict)\n",
        "bands = model_dict.get('bands')\n",
        "response = model_dict.get('response')\n",
        "features = model_dict.get('features')\n",
        "kernal_size = model_dict.get('kernal_size')\n",
        "\n",
        "# load ai model .json file made from EEificationDeployment workflow\n",
        "os.popen(f\"gsutil cp gs://landfire/lucas/pools2fire_tf/{model_name}.json {model_name}.json\").read()\n",
        "with open(f'{model_name}.json') as f:\n",
        "  ai_model_dict = json.load(f)\n",
        "estimator = ai_model_dict.get('estimator')\n",
        "version = ai_model_dict.get('version')\n",
        "project = ai_model_dict.get('project')\n",
        "region = ai_model_dict.get('region')\n",
        "output_dict = ai_model_dict.get('output')\n",
        "print('eeified model info',ai_model_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaiefTdke8XM",
        "outputId": "6b4f52a5-4213-4bc0-a6d5-d1ef8abdc7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://landfire/lucas/pools2fire_tf/sample_v18_rev2_1651770421.json...\n",
            "/ [0 files][    0.0 B/  862.0 B]                                                \r/ [1 files][  862.0 B/  862.0 B]                                                \r\n",
            "Operation completed over 1 objects/862.0 B.                                      \n",
            "tf model info {'uid': 'sample_v18_rev2_1651770421', 'training': 'training_patches_v18_rev2', 'testing': 'testing_patches_v18_rev2', 'validation': 'val_patches_v18_rev2', 'bands': ['elevation', 'slope', 'trasp', 'TMP_p10', 'TMP_median', 'TMP_p90', 'WIND_p10', 'WIND_median', 'WIND_p90', 'SPFH_p10', 'SPFH_median', 'SPFH_p90', 'WDIR_p10', 'WDIR_median', 'WDIR_p90', 'ACPC01_p10', 'ACPC01_median', 'ACPC01_p90'], 'response': ['BP'], 'features': ['elevation', 'slope', 'trasp', 'TMP_p10', 'TMP_median', 'TMP_p90', 'WIND_p10', 'WIND_median', 'WIND_p90', 'SPFH_p10', 'SPFH_median', 'SPFH_p90', 'WDIR_p10', 'WDIR_median', 'WDIR_p90', 'ACPC01_p10', 'ACPC01_median', 'ACPC01_p90', 'BP'], 'kernal_size': 256, 'categorical': [], 'categorical_dict': {}, 'n': 20, 'N': 300, 'file_name': 'sample_v18_rev2_1651770421.json', 'file_dest': 'lucas/pools2fire_tf/sample_v18_rev2_1651770421.json'}\n",
            "eeified model info {'name': 'vgg16unet_model_kdw_sigmoid_mae_v18_rev2', 'bucket': 'landfire', 'folder': 'lucas/pools2fire_tf', 'project': 'pyregence-ee', 'estimator': 'vgg16unet_model_kdw_sigmoid_mae_v18_rev2_ESTIMATOR', 'tf_dir': 'gs://landfire/lucas/pools2fire_tf/vgg16unet_model_kdw_sigmoid_mae_v18_rev2_ESTIMATOR', 'output': 'pools2BP', 'region': 'us-central1', 'eeified_dir': 'gs://landfire/lucas/pools2fire_tf/eeified_vgg16unet_model_kdw_sigmoid_mae_v18_rev2_ESTIMATOR/', 'version': 'v1651845684'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### stack all possible input features we've ever used and then pass json's 'bands' values to image.select()"
      ],
      "metadata": {
        "id": "6UfxIBaulnbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trasp(img):\n",
        "  #(1 - cos(aspect-30))/2\n",
        "  aspect = ee.Image(img)\n",
        "  trasp = (ee.Image.constant(1).subtract(aspect.subtract(30).cos())).divide(2)\n",
        "  return trasp.rename('trasp')\n",
        "\n",
        "srtm = ee.Image('USGS/SRTMGL1_003')\n",
        "ag_fast = ee.Image('projects/pyregence-ee/assets/lucas/conus/Aboveground-Fast_2022_02').rename('agfast').float()\n",
        "ag_med = ee.Image('projects/pyregence-ee/assets/lucas/conus/Aboveground-Medium_2022_02').rename('agmed').float()\n",
        "ag_slo = ee.Image('projects/pyregence-ee/assets/lucas/conus/Aboveground-Slow_2022_02').rename('agslo').float()\n",
        "ag_vfast = ee.Image('projects/pyregence-ee/assets/lucas/conus/Aboveground-Very-Fast_2022_02').rename('agvfast').float()\n",
        "bg_fast = ee.Image('projects/pyregence-ee/assets/lucas/conus/Belowground-Fast_2022_02').rename('bgfast').float()\n",
        "bg_slo = ee.Image('projects/pyregence-ee/assets/lucas/conus/Belowground-Slow_2022_02').rename('bgslo').float()\n",
        "bg_vfast = ee.Image('projects/pyregence-ee/assets/lucas/conus/Belowground-Very-Fast_2022_02').rename('bgvfast').float()\n",
        "c_root = ee.Image('projects/pyregence-ee/assets/lucas/conus/Coarse-Roots_2022_02').rename('croot').float()\n",
        "f_root = ee.Image('projects/pyregence-ee/assets/lucas/conus/Fine-Roots_2022_02').rename('froot').float()\n",
        "fol = ee.Image('projects/pyregence-ee/assets/lucas/conus/Foliage_2022_02').rename('foliage').float()\n",
        "merch = ee.Image('projects/pyregence-ee/assets/lucas/conus/Merchantable_2022_02').rename('merch').float()\n",
        "otherw = ee.Image('projects/pyregence-ee/assets/lucas/conus/Other-Wood_2022_02').rename('otherw').float()\n",
        "snbran = ee.Image('projects/pyregence-ee/assets/lucas/conus/Snag-Branch_2022_02').rename('snbran').float()\n",
        "snstem = ee.Image('projects/pyregence-ee/assets/lucas/conus/Snag-Stem_2022_02').rename('snstem').float()\n",
        "#last_dist = ee.Image('projects/pyregence-ee/assets/lucas/conus/Recent-Disturbance-Masked_2022_02').rename('ldist').float()\n",
        "last_dist = ee.Image('projects/pyregence-ee/assets/lucas/conus/Recent-Disturbance_2022_02').rename('ldist').float()\n",
        "elevation = srtm.select('elevation').float()\n",
        "slope = ee.Terrain.slope(elevation).float()\n",
        "aspect = ee.Terrain.aspect(elevation).float()\n",
        "trasp = trasp(aspect)\n",
        "stateclass = ee.Image('projects/pyregence-ee/assets/lucas/conus/stateclass_onlyforest').rename('sclass')\n",
        "evt = ee.Image('projects/pyregence-ee/assets/conus/landfire/evt/LF2016_EVT_200').rename('evt')\n",
        "age = ee.Image('projects/pyregence-ee/assets/lucas/conus/Age-Class_2022_02').rename('age')\n",
        "pyromes = ee.Image(\"projects/pyregence-ee/assets/conus/usfs/pyromes\").rename('pyrome')\n",
        "\n",
        "# combining carbon pools\n",
        "live_ag = merch.add(otherw).add(fol).rename('live_ag')\n",
        "dead_ag = snstem.add(snbran).add(ag_fast).add(ag_med).add(ag_slo).add(ag_vfast).rename('dead_ag')\n",
        "live_bg = c_root.add(f_root).rename('live_bg')\n",
        "dead_bg = bg_fast.add(bg_slo).add(bg_vfast).rename('dead_bg')\n",
        "\n",
        "ag_all = ag_fast.add(ag_med).add(ag_slo).add(ag_vfast).rename('ag_all')\n",
        "bg_all = bg_fast.add(bg_slo).add(bg_vfast).rename('bg_all')\n",
        "\n",
        "# weather\n",
        "# convert from specific to relative humidity first?\n",
        "spfh_p10 = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_SPFH_2011_2021\").select('SPFH_p10').float()#.unitScale(0, 0.015077958814799786)\n",
        "spfh_median = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_SPFH_2011_2021\").select('SPFH_median').float()#.unitScale(0, 0.018254483118653297)\n",
        "spfh_p90 = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_SPFH_2011_2021\").select('SPFH_p90').float()#.unitScale(0, 0.02191421203315258)\n",
        "\n",
        "# convert from C to F first? \n",
        "tmp_p10 = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_TMP_2011_2021\").select('TMP_p10').float()#.unitScale(-24.222455978393555, 25.068578720092773)\n",
        "tmp_median = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_TMP_2011_2021\").select('TMP_median').float()#.unitScale(-6.363852500915527,\t27.317960739135742)\n",
        "tmp_p90 = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_TMP_2011_2021\").select('TMP_p90').float()#.unitScale(0, 42.87779235839844)\n",
        "\n",
        "wind_p10 = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_WIND_2011_2021\").select('WIND_p10').float()#.unitScale(0, 3.938079833984375)\n",
        "wind_median = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_WIND_2011_2021\").select('WIND_median').float()#.unitScale(0, 9.37088680267334)\n",
        "wind_p90 = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_WIND_2011_2021\").select('WIND_p90').float()#.unitScale(0, 17.119548797607422)\n",
        "\n",
        "# better scaling method than min/max compress? i.e. cosine transform like aspect TRASP equation?\n",
        "wdir_p10 = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_WDIR_2011_2021\").select('WDIR_p10').float()#.unitScale(0, 268.53846153846155)\n",
        "wdir_median = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_WDIR_2011_2021\").select('WDIR_median').float()#.unitScale(0, 332.5821167883212)\n",
        "wdir_p90 = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_WDIR_2011_2021\").select('WDIR_p90').float()#.unitScale(0, 354.5677758318739)\n",
        "\n",
        "# convert from mm/kg^2 to mm first?\n",
        "precip_p10 = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_ACPC01_2011_2021\").select('ACPC01_p10').float()#.unitScale(0, 0.09782296419143677)\n",
        "precip_median = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_ACPC01_2011_2021\").select('ACPC01_median').float()#.unitScale(0, 0.1984066665172577)\n",
        "precip_p90 = ee.Image(\"projects/pyregence-ee/assets/conus/weather/RTMA_ACPC01_2011_2021\").select('ACPC01_p90').float()#.unitScale(0, 16.100494384765625)\n",
        "\n",
        "\n",
        "wx = tmp_p10.addBands(tmp_median).addBands(tmp_p90)\\\n",
        "            .addBands(wind_p10).addBands(wind_median).addBands(wind_p90)\\\n",
        "            .addBands(spfh_p10).addBands(spfh_median).addBands(spfh_p90)\\\n",
        "            .addBands(wdir_p10).addBands(wdir_median).addBands(wdir_p90)\\\n",
        "            .addBands(precip_p10).addBands(precip_median).addBands(precip_p90)\n",
        "\n",
        "\n",
        "\n",
        "all_stack = ag_fast.addBands(ag_med).addBands(ag_slo).addBands(ag_vfast)\\\n",
        "                  .addBands(bg_fast).addBands(bg_slo).addBands(bg_vfast)\\\n",
        "                  .addBands(c_root).addBands(f_root).addBands(fol).addBands(merch)\\\n",
        "                  .addBands(otherw).addBands(snbran).addBands(snstem)\\\n",
        "                  .addBands(last_dist).addBands(elevation).addBands(slope).addBands(aspect).addBands(trasp)\\\n",
        "                  .addBands(stateclass).addBands(evt).addBands(age)\\\n",
        "                  .addBands(live_ag).addBands(dead_ag).addBands(live_bg).addBands(dead_bg)\\\n",
        "                  .addBands(ag_all).addBands(bg_all)\\\n",
        "                  .addBands(pyromes).addBands(wx).unmask()\n",
        "                  \n",
        "\n",
        "print(all_stack.select(bands).bandNames().getInfo())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYk8Erh8kBib",
        "outputId": "cee6dd88-6bff-445e-e7e6-21c2189be852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['elevation', 'slope', 'trasp', 'TMP_p10', 'TMP_median', 'TMP_p90', 'WIND_p10', 'WIND_median', 'WIND_p90', 'SPFH_p10', 'SPFH_median', 'SPFH_p90', 'WDIR_p10', 'WDIR_median', 'WDIR_p90', 'ACPC01_p10', 'ACPC01_median', 'ACPC01_p90']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(estimator)\n",
        "print(version)\n",
        "print(project)\n",
        "print(region)\n",
        "print(output_dict)\n",
        "# v1649682345"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCArONWS7Wtl",
        "outputId": "422002d7-5835-462c-d6d7-44e5db005919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vgg16unet_model_kdw_sigmoid_mae_v18_rev2_ESTIMATOR\n",
            "v1651845684\n",
            "pyregence-ee\n",
            "us-central1\n",
            "pools2BP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array_image = all_stack.select(bands).toArray()\n",
        "print(array_image.bandNames().getInfo())\n",
        "input_depth = all_stack.select(bands).bandNames().size()\n",
        "#print(input_depth.getInfo())\n",
        " # Point to the model hosted on AI Platform.  If you specified a region other\n",
        " # than the default (us-central1) at model creation, specify it here.\n",
        "\n",
        "MODEL_NAME= estimator\n",
        "VERSION_NAME= version\n",
        "PROJECT= project\n",
        "model = ee.Model.fromAiPlatformPredictor(\n",
        "    projectName=PROJECT,\n",
        "    modelName=MODEL_NAME,\n",
        "    version=VERSION_NAME,\n",
        "    #set up model in us-east1, deafult is us-central1\n",
        "    region=region,\n",
        "     # Can be anything, but don't make it too big.\n",
        "     #model trained using 256 array\n",
        "     #tile size needs to be factor of 256 e.g. (4,8,16,32,64,128,256)\n",
        "    inputTileSize=[32, 32],\n",
        "     #if wanting an input overlap the final tile size needs to match the factor\n",
        "     #final tilesize =  tilesize + overlap*2\n",
        "     #e.g. 32 = 24 + (4 * 2)\n",
        "    inputOverlapSize= [32, 32],\n",
        "     # Keep this the same as your training data.\n",
        "    proj=ee.Projection('EPSG:4326').atScale(30),\n",
        "    fixInputProj=True,\n",
        "    # set input shape to depth of input (# of bands in input stack)\n",
        "    inputShapes= {'array':[input_depth]},\n",
        "     # Note the names here need to match what you specified in the\n",
        "     # output dictionary you passed to the EEifier.\n",
        "    outputBands={output_dict: {\n",
        "        'type': ee.PixelType.float(),\n",
        "         #use dimesions if multiple predictions are outputed. \n",
        "         #'dimensions': 1\n",
        "      }\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        " # model.predictImage outputs a one dimensional array image that\n",
        " # packs the output nodes of your model into an array.  These\n",
        " # are class probabilities that you need to unpack into a \n",
        " # multiband image with arrayFlatten().  If you want class\n",
        " # labels, use arrayArgmax() as follows.\n",
        "predictions = model.predictImage(array_image)#//.rename('BP_predicted')\n",
        "print(predictions.bandNames().getInfo())\n",
        "# print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9wRMQaXmzrY",
        "outputId": "9bab9dc8-c3b6-45ba-c093-886efcc4d7df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['array']\n",
            "['pools2BP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grassValley_geom = ee.Image(\"projects/pyregence-ee/assets/lucas/tensorflow/BPpredictions_linear_huber_GrassValley\").geometry()\n",
        "CA = ee.FeatureCollection(\"TIGER/2018/States\").filter(ee.Filter.eq('NAME','California')).first().geometry()\n",
        "bboxes = ee.FeatureCollection(\"projects/pyregence-ee/assets/lucas/tensorflow/inference_bboxes\")\n",
        "ids = bboxes.aggregate_array('system:index').getInfo()\n",
        "#print(ids)\n",
        "# for id in ids:\n",
        "#   id_ = id[-1]\n",
        "#   geom = bboxes.filter(ee.Filter.eq('system:index',id)).first()\n",
        "#   #print(id_)\n",
        "task = ee.batch.Export.image.toAsset(\n",
        "  image=predictions,\n",
        "  assetId= 'projects/pyregence-ee/assets/lucas/tensorflow/' + MODEL_NAME + '_grassValley',\n",
        "  description=MODEL_NAME + '_grassValley',\n",
        "  region=grassValley_geom,\n",
        "  scale=30,\n",
        "  maxPixels=1e12\n",
        "  )\n",
        "\n",
        "task.start()\n",
        "print('exporting prediction to bbox ')"
      ],
      "metadata": {
        "id": "QEKnBcMIrOjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74dbd495-6afa-42ef-9ef8-b6a0af7ca63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exporting prediction to bbox \n"
          ]
        }
      ]
    }
  ]
}